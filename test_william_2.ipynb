{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from mlf import NNClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = glob.glob(r'data/nlp/*.gensim')\n",
    "NUM_TOPICS = [int(re.findall(r'\\d+', s)[0]) for s in NUM_TOPICS]\n",
    "NUM_DAYS = [2, 3, 5, 7, 14, 21, 28, 35, 42, 49, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/Users/williammartin/Library/Mobile Documents/com~apple~CloudDocs/EPFL/3MA/Machine learning for finance/Project/mlf-project/mlf/mlf_utils.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['num_app_prior'] = np.nan\n",
      "/Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/Users/williammartin/Library/Mobile Documents/com~apple~CloudDocs/EPFL/3MA/Machine learning for finance/Project/mlf-project/mlf/mlf_utils.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['num_app_prior'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "reg = NNClassifier()\n",
    "_, _ = reg.generate_xy(num_topics=100, num_days=30)\n",
    "_ = reg.scale_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "pca = PCA(n_components=0.6, svd_solver='full')\n",
    "pca = pca.fit(reg.X_scaled)\n",
    "X = pca.transform(reg.X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    reg.y['y_bin'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=100,\n",
    "                                                    stratify=reg.y['y_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "reg.add_layers(X_train.shape[1], 100, 3)\n",
    "reg.define_optimizer(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/williammartin/anaconda3/envs/epfl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6801 samples, validate on 2916 samples\n",
      "Train on 6801 samples, validate on 2916 samples\n",
      "Epoch 1/300\n",
      "  10/6801 [..............................] - ETA: 1:44 - loss: 0.8819 - accuracy: 0.6000Epoch 1/300\n",
      "6801/6801 [==============================] - 2s 337us/step - loss: 0.8924 - accuracy: 0.5049 - val_loss: 0.6877 - val_accuracy: 0.5511\n",
      "6801/6801 [==============================] - 2s 337us/step - loss: 0.8924 - accuracy: 0.5049 - val_loss: 0.6877 - val_accuracy: 0.5511\n",
      "Epoch 2/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.6598 - accuracy: 0.7000Epoch 2/300\n",
      "6801/6801 [==============================] - 2s 309us/step - loss: 0.7241 - accuracy: 0.5252 - val_loss: 0.7864 - val_accuracy: 0.4496\n",
      "6801/6801 [==============================] - 2s 309us/step - loss: 0.7241 - accuracy: 0.5252 - val_loss: 0.7864 - val_accuracy: 0.4496\n",
      "Epoch 3/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.8280 - accuracy: 0.4000Epoch 3/300\n",
      "6801/6801 [==============================] - 2s 327us/step - loss: 0.7146 - accuracy: 0.5187 - val_loss: 0.7797 - val_accuracy: 0.4558\n",
      "6801/6801 [==============================] - 2s 327us/step - loss: 0.7146 - accuracy: 0.5187 - val_loss: 0.7797 - val_accuracy: 0.4558\n",
      "Epoch 4/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 1.0508 - accuracy: 0.1000Epoch 4/300\n",
      "6801/6801 [==============================] - 2s 344us/step - loss: 0.7130 - accuracy: 0.5396 - val_loss: 0.7145 - val_accuracy: 0.4510\n",
      "6801/6801 [==============================] - 2s 344us/step - loss: 0.7130 - accuracy: 0.5396 - val_loss: 0.7145 - val_accuracy: 0.4510\n",
      "Epoch 5/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.7210 - accuracy: 0.4000Epoch 5/300\n",
      "6801/6801 [==============================] - 2s 305us/step - loss: 0.6953 - accuracy: 0.5467 - val_loss: 0.6834 - val_accuracy: 0.5638\n",
      "6801/6801 [==============================] - 2s 305us/step - loss: 0.6953 - accuracy: 0.5467 - val_loss: 0.6834 - val_accuracy: 0.5638\n",
      "Epoch 6/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.7156 - accuracy: 0.4000Epoch 6/300\n",
      "6801/6801 [==============================] - 2s 342us/step - loss: 0.6901 - accuracy: 0.5467 - val_loss: 0.7093 - val_accuracy: 0.5202\n",
      "6801/6801 [==============================] - 2s 342us/step - loss: 0.6901 - accuracy: 0.5467 - val_loss: 0.7093 - val_accuracy: 0.5202\n",
      "Epoch 7/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.6167 - accuracy: 0.8000Epoch 7/300\n",
      "6801/6801 [==============================] - 2s 291us/step - loss: 0.6842 - accuracy: 0.5643 - val_loss: 0.6882 - val_accuracy: 0.5442\n",
      "6801/6801 [==============================] - 2s 291us/step - loss: 0.6842 - accuracy: 0.5643 - val_loss: 0.6882 - val_accuracy: 0.5442\n",
      "Epoch 8/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.6075 - accuracy: 0.8000Epoch 8/300\n",
      "6801/6801 [==============================] - 2s 302us/step - loss: 0.6732 - accuracy: 0.5762 - val_loss: 0.6872 - val_accuracy: 0.5340\n",
      "6801/6801 [==============================] - 2s 302us/step - loss: 0.6732 - accuracy: 0.5762 - val_loss: 0.6872 - val_accuracy: 0.5340\n",
      "Epoch 9/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.6319 - accuracy: 0.8000Epoch 9/300\n",
      "6801/6801 [==============================] - 2s 368us/step - loss: 0.6721 - accuracy: 0.5811 - val_loss: 0.7010 - val_accuracy: 0.5494\n",
      "6801/6801 [==============================] - 2s 368us/step - loss: 0.6721 - accuracy: 0.5811 - val_loss: 0.7010 - val_accuracy: 0.5494\n",
      "Epoch 10/300\n",
      "  10/6801 [..............................] - ETA: 4s - loss: 0.6938 - accuracy: 0.5000Epoch 10/300\n",
      "6801/6801 [==============================] - 2s 354us/step - loss: 0.6614 - accuracy: 0.5959 - val_loss: 0.7755 - val_accuracy: 0.5508\n",
      "6801/6801 [==============================] - 2s 354us/step - loss: 0.6614 - accuracy: 0.5959 - val_loss: 0.7755 - val_accuracy: 0.5508\n",
      "Epoch 11/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.7388 - accuracy: 0.5000Epoch 11/300\n",
      "6801/6801 [==============================] - 2s 352us/step - loss: 0.6600 - accuracy: 0.6030 - val_loss: 0.6868 - val_accuracy: 0.5580\n",
      "6801/6801 [==============================] - 2s 352us/step - loss: 0.6600 - accuracy: 0.6030 - val_loss: 0.6868 - val_accuracy: 0.5580\n",
      "Epoch 12/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.6478 - accuracy: 0.6000Epoch 12/300\n",
      "6801/6801 [==============================] - 2s 291us/step - loss: 0.6412 - accuracy: 0.6206 - val_loss: 0.7289 - val_accuracy: 0.5504\n",
      "6801/6801 [==============================] - 2s 291us/step - loss: 0.6412 - accuracy: 0.6206 - val_loss: 0.7289 - val_accuracy: 0.5504\n",
      "Epoch 13/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.6596 - accuracy: 0.4000Epoch 13/300\n",
      "6801/6801 [==============================] - 2s 292us/step - loss: 0.6386 - accuracy: 0.6262 - val_loss: 0.7330 - val_accuracy: 0.5364\n",
      "6801/6801 [==============================] - 2s 292us/step - loss: 0.6386 - accuracy: 0.6262 - val_loss: 0.7330 - val_accuracy: 0.5364\n",
      "Epoch 14/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.6143 - accuracy: 0.6000Epoch 14/300\n",
      "6801/6801 [==============================] - 2s 335us/step - loss: 0.6236 - accuracy: 0.6337 - val_loss: 0.7989 - val_accuracy: 0.5580\n",
      "6801/6801 [==============================] - 2s 335us/step - loss: 0.6236 - accuracy: 0.6337 - val_loss: 0.7989 - val_accuracy: 0.5580\n",
      "Epoch 15/300\n",
      "  10/6801 [..............................] - ETA: 5s - loss: 0.5516 - accuracy: 0.7000Epoch 15/300\n",
      "6801/6801 [==============================] - 3s 513us/step - loss: 0.6173 - accuracy: 0.6448 - val_loss: 0.6865 - val_accuracy: 0.5580\n",
      "6801/6801 [==============================] - 3s 513us/step - loss: 0.6173 - accuracy: 0.6448 - val_loss: 0.6865 - val_accuracy: 0.5580\n",
      "Epoch 16/300\n",
      "  10/6801 [..............................] - ETA: 4s - loss: 0.6034 - accuracy: 0.7000Epoch 16/300\n",
      "6801/6801 [==============================] - 2s 320us/step - loss: 0.6068 - accuracy: 0.6624 - val_loss: 0.7431 - val_accuracy: 0.5418\n",
      "6801/6801 [==============================] - 2s 320us/step - loss: 0.6068 - accuracy: 0.6624 - val_loss: 0.7431 - val_accuracy: 0.5418\n",
      "Epoch 17/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.5856 - accuracy: 0.6000Epoch 17/300\n",
      "6801/6801 [==============================] - 2s 339us/step - loss: 0.5963 - accuracy: 0.6650 - val_loss: 0.7670 - val_accuracy: 0.5617\n",
      "6801/6801 [==============================] - 2s 339us/step - loss: 0.5963 - accuracy: 0.6650 - val_loss: 0.7670 - val_accuracy: 0.5617\n",
      "Epoch 18/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.5489 - accuracy: 0.6000Epoch 18/300\n",
      "6801/6801 [==============================] - 2s 315us/step - loss: 0.5817 - accuracy: 0.6784 - val_loss: 0.7483 - val_accuracy: 0.5621\n",
      "6801/6801 [==============================] - 2s 315us/step - loss: 0.5817 - accuracy: 0.6784 - val_loss: 0.7483 - val_accuracy: 0.5621\n",
      "Epoch 19/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.5603 - accuracy: 0.7000Epoch 19/300\n",
      "6801/6801 [==============================] - 2s 300us/step - loss: 0.5686 - accuracy: 0.6884 - val_loss: 0.7747 - val_accuracy: 0.5648\n",
      "6801/6801 [==============================] - 2s 300us/step - loss: 0.5686 - accuracy: 0.6884 - val_loss: 0.7747 - val_accuracy: 0.5648\n",
      "Epoch 20/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.5431 - accuracy: 0.8000Epoch 20/300\n",
      "6801/6801 [==============================] - 2s 311us/step - loss: 0.5618 - accuracy: 0.6980 - val_loss: 0.7878 - val_accuracy: 0.5460\n",
      "6801/6801 [==============================] - 2s 311us/step - loss: 0.5618 - accuracy: 0.6980 - val_loss: 0.7878 - val_accuracy: 0.5460\n",
      "Epoch 21/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/6801 [..............................] - ETA: 1s - loss: 0.2868 - accuracy: 0.9000Epoch 21/300\n",
      "6801/6801 [==============================] - 2s 280us/step - loss: 0.5475 - accuracy: 0.7017 - val_loss: 0.9481 - val_accuracy: 0.5552\n",
      "6801/6801 [==============================] - 2s 280us/step - loss: 0.5475 - accuracy: 0.7017 - val_loss: 0.9481 - val_accuracy: 0.5552\n",
      "Epoch 22/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.5858 - accuracy: 0.6000Epoch 22/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.5440 - accuracy: 0.7134 - val_loss: 0.7550 - val_accuracy: 0.5607\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.5440 - accuracy: 0.7134 - val_loss: 0.7550 - val_accuracy: 0.5607\n",
      "Epoch 23/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4279 - accuracy: 0.9000Epoch 23/300\n",
      "6801/6801 [==============================] - 2s 294us/step - loss: 0.5291 - accuracy: 0.7224 - val_loss: 0.8815 - val_accuracy: 0.5250\n",
      "6801/6801 [==============================] - 2s 294us/step - loss: 0.5291 - accuracy: 0.7224 - val_loss: 0.8815 - val_accuracy: 0.5250\n",
      "Epoch 24/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.3609 - accuracy: 0.8000Epoch 24/300\n",
      "6801/6801 [==============================] - 2s 295us/step - loss: 0.5206 - accuracy: 0.7293 - val_loss: 0.9019 - val_accuracy: 0.5353\n",
      "6801/6801 [==============================] - 2s 295us/step - loss: 0.5206 - accuracy: 0.7293 - val_loss: 0.9019 - val_accuracy: 0.5353\n",
      "Epoch 25/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.7551 - accuracy: 0.6000Epoch 25/300\n",
      "6801/6801 [==============================] - 2s 285us/step - loss: 0.5006 - accuracy: 0.7422 - val_loss: 1.0577 - val_accuracy: 0.5580\n",
      "6801/6801 [==============================] - 2s 285us/step - loss: 0.5006 - accuracy: 0.7422 - val_loss: 1.0577 - val_accuracy: 0.5580\n",
      "Epoch 26/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.3395 - accuracy: 0.7000Epoch 26/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.4895 - accuracy: 0.7461 - val_loss: 0.8474 - val_accuracy: 0.5624\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.4895 - accuracy: 0.7461 - val_loss: 0.8474 - val_accuracy: 0.5624\n",
      "Epoch 27/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4669 - accuracy: 0.8000Epoch 27/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.4827 - accuracy: 0.7506 - val_loss: 0.9209 - val_accuracy: 0.5312\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.4827 - accuracy: 0.7506 - val_loss: 0.9209 - val_accuracy: 0.5312\n",
      "Epoch 28/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.4503 - accuracy: 0.7000Epoch 28/300\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.4711 - accuracy: 0.7562 - val_loss: 0.9923 - val_accuracy: 0.5398\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.4711 - accuracy: 0.7562 - val_loss: 0.9923 - val_accuracy: 0.5398\n",
      "Epoch 29/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.2057 - accuracy: 0.9000Epoch 29/300\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.4658 - accuracy: 0.7602 - val_loss: 0.9238 - val_accuracy: 0.5652\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.4658 - accuracy: 0.7602 - val_loss: 0.9238 - val_accuracy: 0.5652\n",
      "Epoch 30/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.5187 - accuracy: 0.7000Epoch 30/300\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.4578 - accuracy: 0.7647 - val_loss: 0.9821 - val_accuracy: 0.5754\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.4578 - accuracy: 0.7647 - val_loss: 0.9821 - val_accuracy: 0.5754\n",
      "Epoch 31/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.3428 - accuracy: 0.7000Epoch 31/300\n",
      "6801/6801 [==============================] - 2s 305us/step - loss: 0.4398 - accuracy: 0.7800 - val_loss: 0.9620 - val_accuracy: 0.5624\n",
      "6801/6801 [==============================] - 2s 305us/step - loss: 0.4398 - accuracy: 0.7800 - val_loss: 0.9620 - val_accuracy: 0.5624\n",
      "Epoch 32/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4024 - accuracy: 0.7000Epoch 32/300\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.4320 - accuracy: 0.7769 - val_loss: 1.0714 - val_accuracy: 0.5621\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.4320 - accuracy: 0.7769 - val_loss: 1.0714 - val_accuracy: 0.5621\n",
      "Epoch 33/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2021 - accuracy: 1.0000Epoch 33/300\n",
      "6801/6801 [==============================] - 2s 283us/step - loss: 0.4349 - accuracy: 0.7755 - val_loss: 1.0074 - val_accuracy: 0.5744\n",
      "6801/6801 [==============================] - 2s 283us/step - loss: 0.4349 - accuracy: 0.7755 - val_loss: 1.0074 - val_accuracy: 0.5744\n",
      "Epoch 34/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.4200 - accuracy: 0.7000Epoch 34/300\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.4157 - accuracy: 0.7925 - val_loss: 1.0845 - val_accuracy: 0.5676\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.4157 - accuracy: 0.7925 - val_loss: 1.0845 - val_accuracy: 0.5676\n",
      "Epoch 35/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4439 - accuracy: 0.9000Epoch 35/300\n",
      "6801/6801 [==============================] - 3s 369us/step - loss: 0.4139 - accuracy: 0.7896 - val_loss: 0.9806 - val_accuracy: 0.5583\n",
      "6801/6801 [==============================] - 3s 369us/step - loss: 0.4139 - accuracy: 0.7896 - val_loss: 0.9806 - val_accuracy: 0.5583\n",
      "Epoch 36/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.3779 - accuracy: 0.8000Epoch 36/300\n",
      "6801/6801 [==============================] - 2s 298us/step - loss: 0.4093 - accuracy: 0.7853 - val_loss: 1.0307 - val_accuracy: 0.5631\n",
      "6801/6801 [==============================] - 2s 298us/step - loss: 0.4093 - accuracy: 0.7853 - val_loss: 1.0307 - val_accuracy: 0.5631\n",
      "Epoch 37/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.3111 - accuracy: 0.9000Epoch 37/300\n",
      "6801/6801 [==============================] - 2s 307us/step - loss: 0.3948 - accuracy: 0.8018 - val_loss: 1.1580 - val_accuracy: 0.5535\n",
      "6801/6801 [==============================] - 2s 307us/step - loss: 0.3948 - accuracy: 0.8018 - val_loss: 1.1580 - val_accuracy: 0.5535\n",
      "Epoch 38/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1200 - accuracy: 1.0000Epoch 38/300\n",
      "6801/6801 [==============================] - 2s 303us/step - loss: 0.3836 - accuracy: 0.8065 - val_loss: 0.8834 - val_accuracy: 0.5432\n",
      "6801/6801 [==============================] - 2s 303us/step - loss: 0.3836 - accuracy: 0.8065 - val_loss: 0.8834 - val_accuracy: 0.5432\n",
      "Epoch 39/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.3634 - accuracy: 0.8000Epoch 39/300\n",
      "6801/6801 [==============================] - 2s 308us/step - loss: 0.3809 - accuracy: 0.8128 - val_loss: 1.1545 - val_accuracy: 0.5576\n",
      "6801/6801 [==============================] - 2s 308us/step - loss: 0.3809 - accuracy: 0.8128 - val_loss: 1.1545 - val_accuracy: 0.5576\n",
      "Epoch 40/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.4307 - accuracy: 0.8000Epoch 40/300\n",
      "6801/6801 [==============================] - 2s 305us/step - loss: 0.3688 - accuracy: 0.8150 - val_loss: 1.0030 - val_accuracy: 0.5713\n",
      "6801/6801 [==============================] - 2s 305us/step - loss: 0.3688 - accuracy: 0.8150 - val_loss: 1.0030 - val_accuracy: 0.5713\n",
      "Epoch 41/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2621 - accuracy: 0.9000Epoch 41/300\n",
      "6801/6801 [==============================] - 2s 300us/step - loss: 0.3615 - accuracy: 0.8212 - val_loss: 1.1800 - val_accuracy: 0.5631\n",
      "6801/6801 [==============================] - 2s 300us/step - loss: 0.3615 - accuracy: 0.8212 - val_loss: 1.1800 - val_accuracy: 0.5631\n",
      "Epoch 42/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4190 - accuracy: 0.7000Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6801/6801 [==============================] - 2s 283us/step - loss: 0.3572 - accuracy: 0.8233 - val_loss: 1.1384 - val_accuracy: 0.5377\n",
      "6801/6801 [==============================] - 2s 283us/step - loss: 0.3572 - accuracy: 0.8233 - val_loss: 1.1384 - val_accuracy: 0.5377\n",
      "Epoch 43/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.2379 - accuracy: 0.9000Epoch 43/300\n",
      "6801/6801 [==============================] - 2s 300us/step - loss: 0.3447 - accuracy: 0.8321 - val_loss: 1.1821 - val_accuracy: 0.5562\n",
      "6801/6801 [==============================] - 2s 300us/step - loss: 0.3447 - accuracy: 0.8321 - val_loss: 1.1821 - val_accuracy: 0.5562\n",
      "Epoch 44/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.3484 - accuracy: 0.8000Epoch 44/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.3481 - accuracy: 0.8268 - val_loss: 1.2843 - val_accuracy: 0.5542\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.3481 - accuracy: 0.8268 - val_loss: 1.2843 - val_accuracy: 0.5542\n",
      "Epoch 45/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.5097 - accuracy: 0.8000Epoch 45/300\n",
      "6801/6801 [==============================] - 2s 280us/step - loss: 0.3312 - accuracy: 0.8378 - val_loss: 1.2953 - val_accuracy: 0.5624\n",
      "6801/6801 [==============================] - 2s 280us/step - loss: 0.3312 - accuracy: 0.8378 - val_loss: 1.2953 - val_accuracy: 0.5624\n",
      "Epoch 46/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.3200 - accuracy: 0.9000Epoch 46/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.3435 - accuracy: 0.8291 - val_loss: 1.0412 - val_accuracy: 0.5600\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.3435 - accuracy: 0.8291 - val_loss: 1.0412 - val_accuracy: 0.5600\n",
      "Epoch 47/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2477 - accuracy: 0.9000Epoch 47/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.3310 - accuracy: 0.8358 - val_loss: 1.3105 - val_accuracy: 0.5806\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.3310 - accuracy: 0.8358 - val_loss: 1.3105 - val_accuracy: 0.5806\n",
      "Epoch 48/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1713 - accuracy: 1.0000Epoch 48/300\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.3157 - accuracy: 0.8437 - val_loss: 1.4607 - val_accuracy: 0.5686\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.3157 - accuracy: 0.8437 - val_loss: 1.4607 - val_accuracy: 0.5686\n",
      "Epoch 49/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2181 - accuracy: 1.0000Epoch 49/300\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.3201 - accuracy: 0.8418 - val_loss: 1.2358 - val_accuracy: 0.5682\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.3201 - accuracy: 0.8418 - val_loss: 1.2358 - val_accuracy: 0.5682\n",
      "Epoch 50/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1963 - accuracy: 0.9000Epoch 50/300\n",
      "6801/6801 [==============================] - 2s 276us/step - loss: 0.3110 - accuracy: 0.8452 - val_loss: 1.3987 - val_accuracy: 0.5713\n",
      "6801/6801 [==============================] - 2s 276us/step - loss: 0.3110 - accuracy: 0.8452 - val_loss: 1.3987 - val_accuracy: 0.5713\n",
      "Epoch 51/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.1170 - accuracy: 1.0000Epoch 51/300\n",
      "6801/6801 [==============================] - 2s 274us/step - loss: 0.3150 - accuracy: 0.8525 - val_loss: 1.1701 - val_accuracy: 0.5586\n",
      "6801/6801 [==============================] - 2s 274us/step - loss: 0.3150 - accuracy: 0.8525 - val_loss: 1.1701 - val_accuracy: 0.5586\n",
      "Epoch 52/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4190 - accuracy: 0.8000Epoch 52/300\n",
      "6801/6801 [==============================] - 2s 273us/step - loss: 0.2978 - accuracy: 0.8530 - val_loss: 1.4565 - val_accuracy: 0.5703\n",
      "6801/6801 [==============================] - 2s 273us/step - loss: 0.2978 - accuracy: 0.8530 - val_loss: 1.4565 - val_accuracy: 0.5703\n",
      "Epoch 53/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2703 - accuracy: 0.8000Epoch 53/300\n",
      "6801/6801 [==============================] - 2s 273us/step - loss: 0.2966 - accuracy: 0.8516 - val_loss: 1.4737 - val_accuracy: 0.5652\n",
      "6801/6801 [==============================] - 2s 273us/step - loss: 0.2966 - accuracy: 0.8516 - val_loss: 1.4737 - val_accuracy: 0.5652\n",
      "Epoch 54/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.2119 - accuracy: 1.0000Epoch 54/300\n",
      "6801/6801 [==============================] - 2s 275us/step - loss: 0.2970 - accuracy: 0.8537 - val_loss: 1.4016 - val_accuracy: 0.5494\n",
      "6801/6801 [==============================] - 2s 275us/step - loss: 0.2970 - accuracy: 0.8537 - val_loss: 1.4016 - val_accuracy: 0.5494\n",
      "Epoch 55/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2499 - accuracy: 0.8000Epoch 55/300\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2874 - accuracy: 0.8616 - val_loss: 1.5137 - val_accuracy: 0.5638\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2874 - accuracy: 0.8616 - val_loss: 1.5137 - val_accuracy: 0.5638\n",
      "Epoch 56/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2025 - accuracy: 0.9000Epoch 56/300\n",
      "6801/6801 [==============================] - 2s 288us/step - loss: 0.2759 - accuracy: 0.8643 - val_loss: 1.5495 - val_accuracy: 0.5658\n",
      "6801/6801 [==============================] - 2s 288us/step - loss: 0.2759 - accuracy: 0.8643 - val_loss: 1.5495 - val_accuracy: 0.5658\n",
      "Epoch 57/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.2390 - accuracy: 0.9000Epoch 57/300\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2864 - accuracy: 0.8590 - val_loss: 1.4140 - val_accuracy: 0.5607\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2864 - accuracy: 0.8590 - val_loss: 1.4140 - val_accuracy: 0.5607\n",
      "Epoch 58/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2031 - accuracy: 0.8000Epoch 58/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2738 - accuracy: 0.8618 - val_loss: 1.4753 - val_accuracy: 0.5562\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2738 - accuracy: 0.8618 - val_loss: 1.4753 - val_accuracy: 0.5562\n",
      "Epoch 59/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.3157 - accuracy: 0.7000Epoch 59/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2767 - accuracy: 0.8635 - val_loss: 1.4785 - val_accuracy: 0.5398\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2767 - accuracy: 0.8635 - val_loss: 1.4785 - val_accuracy: 0.5398\n",
      "Epoch 60/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2384 - accuracy: 0.9000Epoch 60/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2740 - accuracy: 0.8665 - val_loss: 1.6487 - val_accuracy: 0.5617\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2740 - accuracy: 0.8665 - val_loss: 1.6487 - val_accuracy: 0.5617\n",
      "Epoch 61/300\n",
      "  10/6801 [..............................] - ETA: 3s - loss: 0.2495 - accuracy: 1.0000Epoch 61/300\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2742 - accuracy: 0.8690 - val_loss: 1.5407 - val_accuracy: 0.5703\n",
      "6801/6801 [==============================] - 2s 279us/step - loss: 0.2742 - accuracy: 0.8690 - val_loss: 1.5407 - val_accuracy: 0.5703\n",
      "Epoch 62/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.3468 - accuracy: 0.8000Epoch 62/300\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2693 - accuracy: 0.8675 - val_loss: 1.4363 - val_accuracy: 0.5610\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2693 - accuracy: 0.8675 - val_loss: 1.4363 - val_accuracy: 0.5610\n",
      "Epoch 63/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.1843 - accuracy: 0.9000Epoch 63/300\n",
      "6801/6801 [==============================] - 2s 280us/step - loss: 0.2554 - accuracy: 0.8784 - val_loss: 1.8540 - val_accuracy: 0.5600\n",
      "6801/6801 [==============================] - 2s 280us/step - loss: 0.2554 - accuracy: 0.8784 - val_loss: 1.8540 - val_accuracy: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2264 - accuracy: 0.8000Epoch 64/300\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.2627 - accuracy: 0.8738 - val_loss: 1.5503 - val_accuracy: 0.5662\n",
      "6801/6801 [==============================] - 2s 281us/step - loss: 0.2627 - accuracy: 0.8738 - val_loss: 1.5503 - val_accuracy: 0.5662\n",
      "Epoch 65/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2257 - accuracy: 0.9000Epoch 65/300\n",
      "6801/6801 [==============================] - 2s 276us/step - loss: 0.2506 - accuracy: 0.8771 - val_loss: 1.6435 - val_accuracy: 0.5604\n",
      "6801/6801 [==============================] - 2s 276us/step - loss: 0.2506 - accuracy: 0.8771 - val_loss: 1.6435 - val_accuracy: 0.5604\n",
      "Epoch 66/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.0776 - accuracy: 1.0000Epoch 66/300\n",
      "6801/6801 [==============================] - 2s 272us/step - loss: 0.2542 - accuracy: 0.8775 - val_loss: 1.7273 - val_accuracy: 0.5532\n",
      "6801/6801 [==============================] - 2s 272us/step - loss: 0.2542 - accuracy: 0.8775 - val_loss: 1.7273 - val_accuracy: 0.5532\n",
      "Epoch 67/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1248 - accuracy: 1.0000Epoch 67/300\n",
      "6801/6801 [==============================] - 2s 275us/step - loss: 0.2534 - accuracy: 0.8800 - val_loss: 1.5349 - val_accuracy: 0.5710\n",
      "6801/6801 [==============================] - 2s 275us/step - loss: 0.2534 - accuracy: 0.8800 - val_loss: 1.5349 - val_accuracy: 0.5710\n",
      "Epoch 68/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1269 - accuracy: 1.0000Epoch 68/300\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2450 - accuracy: 0.8790 - val_loss: 1.4402 - val_accuracy: 0.5583\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2450 - accuracy: 0.8790 - val_loss: 1.4402 - val_accuracy: 0.5583\n",
      "Epoch 69/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2039 - accuracy: 0.9000Epoch 69/300\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2413 - accuracy: 0.8840 - val_loss: 1.6337 - val_accuracy: 0.5593\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2413 - accuracy: 0.8840 - val_loss: 1.6337 - val_accuracy: 0.5593\n",
      "Epoch 70/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.0537 - accuracy: 1.0000Epoch 70/300\n",
      "6801/6801 [==============================] - 2s 276us/step - loss: 0.2514 - accuracy: 0.8797 - val_loss: 1.6982 - val_accuracy: 0.5545\n",
      "6801/6801 [==============================] - 2s 276us/step - loss: 0.2514 - accuracy: 0.8797 - val_loss: 1.6982 - val_accuracy: 0.5545\n",
      "Epoch 71/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.6165 - accuracy: 0.8000Epoch 71/300\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2392 - accuracy: 0.8828 - val_loss: 1.7613 - val_accuracy: 0.5727\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2392 - accuracy: 0.8828 - val_loss: 1.7613 - val_accuracy: 0.5727\n",
      "Epoch 72/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.7762 - accuracy: 0.9000Epoch 72/300\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2612 - accuracy: 0.8741 - val_loss: 1.5715 - val_accuracy: 0.5545\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2612 - accuracy: 0.8741 - val_loss: 1.5715 - val_accuracy: 0.5545\n",
      "Epoch 73/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1416 - accuracy: 1.0000Epoch 73/300\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2388 - accuracy: 0.8844 - val_loss: 1.5171 - val_accuracy: 0.5638\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2388 - accuracy: 0.8844 - val_loss: 1.5171 - val_accuracy: 0.5638\n",
      "Epoch 74/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0981 - accuracy: 1.0000Epoch 74/300\n",
      "6801/6801 [==============================] - 2s 297us/step - loss: 0.2246 - accuracy: 0.8894 - val_loss: 1.7597 - val_accuracy: 0.5556\n",
      "6801/6801 [==============================] - 2s 297us/step - loss: 0.2246 - accuracy: 0.8894 - val_loss: 1.7597 - val_accuracy: 0.5556\n",
      "Epoch 75/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.1572 - accuracy: 1.0000Epoch 75/300\n",
      "6801/6801 [==============================] - 2s 272us/step - loss: 0.2305 - accuracy: 0.8849 - val_loss: 1.8656 - val_accuracy: 0.5686\n",
      "6801/6801 [==============================] - 2s 272us/step - loss: 0.2305 - accuracy: 0.8849 - val_loss: 1.8656 - val_accuracy: 0.5686\n",
      "Epoch 76/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1213 - accuracy: 1.0000Epoch 76/300\n",
      "6801/6801 [==============================] - 2s 272us/step - loss: 0.2350 - accuracy: 0.8833 - val_loss: 1.8024 - val_accuracy: 0.5590\n",
      "6801/6801 [==============================] - 2s 272us/step - loss: 0.2350 - accuracy: 0.8833 - val_loss: 1.8024 - val_accuracy: 0.5590\n",
      "Epoch 77/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.5667 - accuracy: 0.8000Epoch 77/300\n",
      "6801/6801 [==============================] - 2s 268us/step - loss: 0.2399 - accuracy: 0.8812 - val_loss: 1.6602 - val_accuracy: 0.5446\n",
      "6801/6801 [==============================] - 2s 268us/step - loss: 0.2399 - accuracy: 0.8812 - val_loss: 1.6602 - val_accuracy: 0.5446\n",
      "Epoch 78/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.1809 - accuracy: 1.0000Epoch 78/300\n",
      "6801/6801 [==============================] - 2s 275us/step - loss: 0.2434 - accuracy: 0.8812 - val_loss: 1.6217 - val_accuracy: 0.5590\n",
      "6801/6801 [==============================] - 2s 275us/step - loss: 0.2434 - accuracy: 0.8812 - val_loss: 1.6217 - val_accuracy: 0.5590\n",
      "Epoch 79/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1895 - accuracy: 1.0000Epoch 79/300\n",
      "6801/6801 [==============================] - 2s 286us/step - loss: 0.2214 - accuracy: 0.8933 - val_loss: 1.8747 - val_accuracy: 0.5446\n",
      "6801/6801 [==============================] - 2s 286us/step - loss: 0.2214 - accuracy: 0.8933 - val_loss: 1.8747 - val_accuracy: 0.5446\n",
      "Epoch 80/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0750 - accuracy: 1.0000Epoch 80/300\n",
      "6801/6801 [==============================] - 2s 307us/step - loss: 0.2130 - accuracy: 0.8947 - val_loss: 1.9576 - val_accuracy: 0.5566\n",
      "6801/6801 [==============================] - 2s 307us/step - loss: 0.2130 - accuracy: 0.8947 - val_loss: 1.9576 - val_accuracy: 0.5566\n",
      "Epoch 81/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0905 - accuracy: 1.0000Epoch 81/300\n",
      "6801/6801 [==============================] - 2s 291us/step - loss: 0.2271 - accuracy: 0.8872 - val_loss: 1.6763 - val_accuracy: 0.55830s - loss: 0.2198 \n",
      "6801/6801 [==============================] - 2s 291us/step - loss: 0.2271 - accuracy: 0.8872 - val_loss: 1.6763 - val_accuracy: 0.5583\n",
      "Epoch 82/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0168 - accuracy: 1.0000Epoch 82/300\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2242 - accuracy: 0.8894 - val_loss: 1.8099 - val_accuracy: 0.55970s\n",
      "6801/6801 [==============================] - 2s 278us/step - loss: 0.2242 - accuracy: 0.8894 - val_loss: 1.8099 - val_accuracy: 0.5597\n",
      "Epoch 83/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.1347 - accuracy: 1.0000Epoch 83/300\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.2222 - accuracy: 0.8905 - val_loss: 1.7400 - val_accuracy: 0.5658\n",
      "6801/6801 [==============================] - 2s 282us/step - loss: 0.2222 - accuracy: 0.8905 - val_loss: 1.7400 - val_accuracy: 0.5658\n",
      "Epoch 84/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2966 - accuracy: 0.7000Epoch 84/300\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2343 - accuracy: 0.8831 - val_loss: 1.8351 - val_accuracy: 0.5586\n",
      "6801/6801 [==============================] - 2s 277us/step - loss: 0.2343 - accuracy: 0.8831 - val_loss: 1.8351 - val_accuracy: 0.5586\n",
      "Epoch 85/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2105 - accuracy: 0.9000Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6801/6801 [==============================] - 4s 540us/step - loss: 0.2204 - accuracy: 0.8943 - val_loss: 1.8351 - val_accuracy: 0.56340s - loss: 0.2195  - ETA: 0s - loss: 0.2198 - accuracy: 0.89 - ETA: 0s - loss: 0.2198 - accuracy: 0.89\n",
      "6801/6801 [==============================] - 4s 540us/step - loss: 0.2204 - accuracy: 0.8943 - val_loss: 1.8351 - val_accuracy: 0.5634\n",
      "Epoch 86/300\n",
      "  10/6801 [..............................] - ETA: 6s - loss: 0.1202 - accuracy: 1.0000Epoch 86/300\n",
      "6801/6801 [==============================] - 3s 374us/step - loss: 0.2471 - accuracy: 0.8766 - val_loss: 1.8637 - val_accuracy: 0.5460\n",
      "6801/6801 [==============================] - 3s 374us/step - loss: 0.2471 - accuracy: 0.8766 - val_loss: 1.8637 - val_accuracy: 0.5460\n",
      "Epoch 87/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1895 - accuracy: 0.9000Epoch 87/300\n",
      "6801/6801 [==============================] - 2s 320us/step - loss: 0.2207 - accuracy: 0.8944 - val_loss: 1.7920 - val_accuracy: 0.5586\n",
      "6801/6801 [==============================] - 2s 320us/step - loss: 0.2207 - accuracy: 0.8944 - val_loss: 1.7920 - val_accuracy: 0.5586\n",
      "Epoch 88/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1645 - accuracy: 1.0000Epoch 88/300\n",
      "6801/6801 [==============================] - 3s 411us/step - loss: 0.2140 - accuracy: 0.8978 - val_loss: 1.8098 - val_accuracy: 0.5597\n",
      "6801/6801 [==============================] - 3s 411us/step - loss: 0.2140 - accuracy: 0.8978 - val_loss: 1.8098 - val_accuracy: 0.5597\n",
      "Epoch 89/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.0336 - accuracy: 1.0000Epoch 89/300\n",
      "6801/6801 [==============================] - 3s 375us/step - loss: 0.2132 - accuracy: 0.8965 - val_loss: 1.9547 - val_accuracy: 0.5665\n",
      "6801/6801 [==============================] - 3s 375us/step - loss: 0.2132 - accuracy: 0.8965 - val_loss: 1.9547 - val_accuracy: 0.5665\n",
      "Epoch 90/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.1381 - accuracy: 1.0000Epoch 90/300\n",
      "6801/6801 [==============================] - 2s 351us/step - loss: 0.2328 - accuracy: 0.8905 - val_loss: 1.9031 - val_accuracy: 0.5638\n",
      "6801/6801 [==============================] - 2s 351us/step - loss: 0.2328 - accuracy: 0.8905 - val_loss: 1.9031 - val_accuracy: 0.5638\n",
      "Epoch 91/300\n",
      "  10/6801 [..............................] - ETA: 3s - loss: 0.3146 - accuracy: 0.9000Epoch 91/300\n",
      "6801/6801 [==============================] - 2s 343us/step - loss: 0.2179 - accuracy: 0.8978 - val_loss: 1.7240 - val_accuracy: 0.5412\n",
      "6801/6801 [==============================] - 2s 343us/step - loss: 0.2179 - accuracy: 0.8978 - val_loss: 1.7240 - val_accuracy: 0.5412\n",
      "Epoch 92/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1619 - accuracy: 0.9000Epoch 92/300\n",
      "6801/6801 [==============================] - 3s 398us/step - loss: 0.2016 - accuracy: 0.9015 - val_loss: 1.9068 - val_accuracy: 0.5634\n",
      "6801/6801 [==============================] - 3s 398us/step - loss: 0.2016 - accuracy: 0.9015 - val_loss: 1.9068 - val_accuracy: 0.5634\n",
      "Epoch 93/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1631 - accuracy: 1.0000Epoch 93/300\n",
      "6801/6801 [==============================] - 3s 378us/step - loss: 0.2123 - accuracy: 0.8987 - val_loss: 2.0392 - val_accuracy: 0.5624\n",
      "6801/6801 [==============================] - 3s 378us/step - loss: 0.2123 - accuracy: 0.8987 - val_loss: 2.0392 - val_accuracy: 0.5624\n",
      "Epoch 94/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1424 - accuracy: 0.9000Epoch 94/300\n",
      "6801/6801 [==============================] - 3s 395us/step - loss: 0.2061 - accuracy: 0.9041 - val_loss: 2.0018 - val_accuracy: 0.5638\n",
      "6801/6801 [==============================] - 3s 395us/step - loss: 0.2061 - accuracy: 0.9041 - val_loss: 2.0018 - val_accuracy: 0.5638\n",
      "Epoch 95/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.3693 - accuracy: 0.9000Epoch 95/300\n",
      "6801/6801 [==============================] - 3s 370us/step - loss: 0.2117 - accuracy: 0.9019 - val_loss: 1.7127 - val_accuracy: 0.5532\n",
      "6801/6801 [==============================] - 3s 370us/step - loss: 0.2117 - accuracy: 0.9019 - val_loss: 1.7127 - val_accuracy: 0.5532\n",
      "Epoch 96/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.0431 - accuracy: 1.0000Epoch 96/300\n",
      "6801/6801 [==============================] - 2s 322us/step - loss: 0.2057 - accuracy: 0.8956 - val_loss: 1.7844 - val_accuracy: 0.5593\n",
      "6801/6801 [==============================] - 2s 322us/step - loss: 0.2057 - accuracy: 0.8956 - val_loss: 1.7844 - val_accuracy: 0.5593\n",
      "Epoch 97/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0660 - accuracy: 1.0000Epoch 97/300\n",
      "6801/6801 [==============================] - 2s 302us/step - loss: 0.2176 - accuracy: 0.8959 - val_loss: 2.0590 - val_accuracy: 0.5583\n",
      "6801/6801 [==============================] - 2s 302us/step - loss: 0.2176 - accuracy: 0.8959 - val_loss: 2.0590 - val_accuracy: 0.5583\n",
      "Epoch 98/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.1409 - accuracy: 1.0000Epoch 98/300\n",
      "6801/6801 [==============================] - 2s 298us/step - loss: 0.2106 - accuracy: 0.8999 - val_loss: 1.6350 - val_accuracy: 0.5689\n",
      "6801/6801 [==============================] - 2s 298us/step - loss: 0.2106 - accuracy: 0.8999 - val_loss: 1.6350 - val_accuracy: 0.5689\n",
      "Epoch 99/300\n",
      "  10/6801 [..............................] - ETA: 3s - loss: 0.1533 - accuracy: 1.0000Epoch 99/300\n",
      "6801/6801 [==============================] - 3s 369us/step - loss: 0.2202 - accuracy: 0.8958 - val_loss: 1.8536 - val_accuracy: 0.5470\n",
      "6801/6801 [==============================] - 3s 369us/step - loss: 0.2202 - accuracy: 0.8958 - val_loss: 1.8536 - val_accuracy: 0.5470\n",
      "Epoch 100/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0410 - accuracy: 1.0000Epoch 100/300\n",
      "6801/6801 [==============================] - 2s 363us/step - loss: 0.2041 - accuracy: 0.9025 - val_loss: 1.7367 - val_accuracy: 0.5617\n",
      "6801/6801 [==============================] - 2s 363us/step - loss: 0.2041 - accuracy: 0.9025 - val_loss: 1.7367 - val_accuracy: 0.5617\n",
      "Epoch 101/300\n",
      "  10/6801 [..............................] - ETA: 3s - loss: 0.0722 - accuracy: 1.0000Epoch 101/300\n",
      "6801/6801 [==============================] - 2s 356us/step - loss: 0.2179 - accuracy: 0.8958 - val_loss: 2.0017 - val_accuracy: 0.5621\n",
      "6801/6801 [==============================] - 2s 356us/step - loss: 0.2179 - accuracy: 0.8958 - val_loss: 2.0017 - val_accuracy: 0.5621\n",
      "Epoch 102/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.2807 - accuracy: 0.8000Epoch 102/300\n",
      "6801/6801 [==============================] - 2s 353us/step - loss: 0.2077 - accuracy: 0.8985 - val_loss: 1.8010 - val_accuracy: 0.5693\n",
      "6801/6801 [==============================] - 2s 353us/step - loss: 0.2077 - accuracy: 0.8985 - val_loss: 1.8010 - val_accuracy: 0.5693\n",
      "Epoch 103/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2106 - accuracy: 0.8000Epoch 103/300\n",
      "6801/6801 [==============================] - 2s 321us/step - loss: 0.1997 - accuracy: 0.9044 - val_loss: 1.7947 - val_accuracy: 0.5621\n",
      "6801/6801 [==============================] - 2s 321us/step - loss: 0.1997 - accuracy: 0.9044 - val_loss: 1.7947 - val_accuracy: 0.5621\n",
      "Epoch 104/300\n",
      "  10/6801 [..............................] - ETA: 4s - loss: 0.0635 - accuracy: 1.0000Epoch 104/300\n",
      "6801/6801 [==============================] - 3s 381us/step - loss: 0.1905 - accuracy: 0.9066 - val_loss: 2.0386 - val_accuracy: 0.5631\n",
      "6801/6801 [==============================] - 3s 381us/step - loss: 0.1905 - accuracy: 0.9066 - val_loss: 2.0386 - val_accuracy: 0.5631\n",
      "Epoch 105/300\n",
      "  10/6801 [..............................] - ETA: 1s - loss: 0.0453 - accuracy: 1.0000Epoch 105/300\n",
      "6801/6801 [==============================] - 2s 319us/step - loss: 0.2067 - accuracy: 0.8994 - val_loss: 2.1258 - val_accuracy: 0.5614\n",
      "6801/6801 [==============================] - 2s 319us/step - loss: 0.2067 - accuracy: 0.8994 - val_loss: 2.1258 - val_accuracy: 0.5614\n",
      "Epoch 106/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.2162 - accuracy: 0.8000Epoch 106/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6801/6801 [==============================] - 2s 329us/step - loss: 0.2079 - accuracy: 0.9010 - val_loss: 1.8380 - val_accuracy: 0.5665\n",
      "6801/6801 [==============================] - 2s 329us/step - loss: 0.2079 - accuracy: 0.9010 - val_loss: 1.8380 - val_accuracy: 0.5665\n",
      "Epoch 107/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.4370 - accuracy: 0.7000Epoch 107/300\n",
      "6801/6801 [==============================] - 2s 286us/step - loss: 0.1953 - accuracy: 0.9040 - val_loss: 1.8543 - val_accuracy: 0.5521\n",
      "6801/6801 [==============================] - 2s 286us/step - loss: 0.1953 - accuracy: 0.9040 - val_loss: 1.8543 - val_accuracy: 0.5521\n",
      "Epoch 108/300\n",
      "  10/6801 [..............................] - ETA: 2s - loss: 0.0873 - accuracy: 1.0000Epoch 108/300\n",
      " 510/6801 [=>............................] - ETA: 1s - loss: 0.2463 - accuracy: 0.8765"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ff155e03313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   callbacks=[tb])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ff155e03313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   callbacks=[tb])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/epfl/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 10 #X_train.shape[1]\n",
    "\n",
    "tb = tf.compat.v1.keras.callbacks.TensorBoard(histogram_freq=1, write_grads=True, profile_batch=0)\n",
    "\n",
    "history = reg.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size,\n",
    "                  verbose=1,\n",
    "                  callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
